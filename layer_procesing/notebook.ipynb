{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('c:/Users/SEJC94056/Documents/AADT_CodeProject/GAT-Applied/layer_procesing')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# BASE_DIR = Path(__file__).resolve().parent\n",
    "BASE_DIR = Path.cwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ODM_FILE = BASE_DIR / 'data' / 'Mobile Data' / 'odm.csv' \n",
    "REAL_NETWORK_MAIN_DIR = BASE_DIR / \"/data/geopackages\"\n",
    "NODES_REAL_NETWORK = REAL_NETWORK_MAIN_DIR / \"joined_emme_network_nodes_2000_2024.gpkg\"\n",
    "LINKS_REAL_NETWORK = REAL_NETWORK_MAIN_DIR / \"joined_emme_network_links_2000_2024.gpkg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('c:/Users/SEJC94056/Documents/AADT_CodeProject/GAT-Applied/layer_procesing/data/Mobile Data/odm.csv')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ODM_FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "      <th>origin_zone</th>\n",
       "      <th>destination_zone</th>\n",
       "      <th>people</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-10-03</td>\n",
       "      <td>12</td>\n",
       "      <td>Ryd</td>\n",
       "      <td>Ryd</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-10-13</td>\n",
       "      <td>6</td>\n",
       "      <td>Ryd</td>\n",
       "      <td>Ryd</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-10-16</td>\n",
       "      <td>7</td>\n",
       "      <td>Ryd</td>\n",
       "      <td>Ryd</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-09-27</td>\n",
       "      <td>19</td>\n",
       "      <td>Ryd</td>\n",
       "      <td>Ryd</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-09-29</td>\n",
       "      <td>1</td>\n",
       "      <td>Ryd</td>\n",
       "      <td>Ryd</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  hour origin_zone destination_zone  people\n",
       "0  2022-10-03    12         Ryd              Ryd     114\n",
       "1  2022-10-13     6         Ryd              Ryd      51\n",
       "2  2022-10-16     7         Ryd              Ryd       7\n",
       "3  2022-09-27    19         Ryd              Ryd     131\n",
       "4  2022-09-29     1         Ryd              Ryd      14"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OD_Data = pd.read_csv(ODM_FILE, sep=\";\")\n",
    "OD_Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'hour', 'origin_zone', 'destination_zone', 'people'], dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OD_Data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create the datetime column combining 'date' and 'hour'\n",
    "datetime_col = pd.to_datetime(OD_Data['date'].astype(str) + ' ' + OD_Data['hour'].astype(str) + ':00:00')\n",
    "\n",
    "# Insert 'datetime' column just after 'hour'\n",
    "hour_idx = OD_Data.columns.get_loc('hour')\n",
    "OD_Data.insert(hour_idx + 1, 'datetime', datetime_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot insert origin_zone_id, already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_612\\2884868189.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      3\u001b[39m origin_zone_id_col = OD_Data[\u001b[33m'origin_zone'\u001b[39m].map(origin_dict)\n\u001b[32m      4\u001b[39m \n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Insert 'origin_zone_id' just after 'origin_zone'\u001b[39;00m\n\u001b[32m      6\u001b[39m origin_zone_idx = OD_Data.columns.get_loc(\u001b[33m'origin_zone'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m OD_Data.insert(origin_zone_idx + \u001b[32m1\u001b[39m, \u001b[33m'origin_zone_id'\u001b[39m, origin_zone_id_col)\n\u001b[32m      8\u001b[39m \n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Step 3: Create destination_zone_id dictionary and map\u001b[39;00m\n\u001b[32m     10\u001b[39m destination_dict = {zone: idx \u001b[38;5;28;01mfor\u001b[39;00m idx, zone \u001b[38;5;28;01min\u001b[39;00m enumerate(OD_Data[\u001b[33m'destination_zone'\u001b[39m].unique())}\n",
      "\u001b[32mc:\\Users\\SEJC94056\\Documents\\AADT_CodeProject\\GAT-Applied\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, loc, column, value, allow_duplicates)\u001b[39m\n\u001b[32m   5154\u001b[39m                 \u001b[33m\"'self.flags.allows_duplicate_labels' is False.\"\u001b[39m\n\u001b[32m   5155\u001b[39m             )\n\u001b[32m   5156\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m allow_duplicates \u001b[38;5;28;01mand\u001b[39;00m column \u001b[38;5;28;01min\u001b[39;00m self.columns:\n\u001b[32m   5157\u001b[39m             \u001b[38;5;66;03m# Should this be a different kind of error??\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m5158\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m ValueError(f\"cannot insert {column}, already exists\")\n\u001b[32m   5159\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m is_integer(loc):\n\u001b[32m   5160\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m TypeError(\u001b[33m\"loc must be int\"\u001b[39m)\n\u001b[32m   5161\u001b[39m         \u001b[38;5;66;03m# convert non stdlib ints to satisfy typing checks\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: cannot insert origin_zone_id, already exists"
     ]
    }
   ],
   "source": [
    "# Step 2: Create origin_zone_id dictionary and map\n",
    "origin_dict = {zone: idx for idx, zone in enumerate(OD_Data['origin_zone'].unique())}\n",
    "origin_zone_id_col = OD_Data['origin_zone'].map(origin_dict)\n",
    "\n",
    "# Insert 'origin_zone_id' just after 'origin_zone'\n",
    "origin_zone_idx = OD_Data.columns.get_loc('origin_zone')\n",
    "OD_Data.insert(origin_zone_idx + 1, 'origin_zone_id', origin_zone_id_col)\n",
    "\n",
    "# Step 3: Create destination_zone_id dictionary and map\n",
    "destination_dict = {zone: idx for idx, zone in enumerate(OD_Data['destination_zone'].unique())}\n",
    "destination_zone_id_col = OD_Data['destination_zone'].map(destination_dict)\n",
    "\n",
    "# Insert 'destination_zone_id' just after 'destination_zone'\n",
    "destination_zone_idx = OD_Data.columns.get_loc('destination_zone')\n",
    "OD_Data.insert(destination_zone_idx + 1, 'destination_zone_id', destination_zone_id_col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OD_Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "route = r\"C:/Users/SEJC94056/Documents/General Layers/Emme_Processed_Layers/emme_links_ready_to_join.gpkg\"\n",
    "emme_links = gpd.read_file(route, layer=\"emme_links_ready_to_join\", force_2d=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atributos comunes: ['LENGTH', 'TYPE', 'LANES', 'VDF', 'DATA1', 'DATA2', 'DATA3', '@ad_filter', '@adlbs', '@adlbu', '@adpb', '@atk', '@fvkl', '@hast', '@juhas', '@jukap', '@komun', '@lbef', '@vkat', '@vnr', '@vstng', '@vtyp']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import LineString, MultiLineString\n",
    "from shapely.measurement import frechet_distance\n",
    "from shapely.ops import linemerge\n",
    "\n",
    "# -----------------------------\n",
    "# Funciones auxiliares\n",
    "# -----------------------------\n",
    "def ensure_linestring(geom):\n",
    "    if isinstance(geom, LineString):\n",
    "        return geom\n",
    "    elif isinstance(geom, MultiLineString):\n",
    "        merged = linemerge(geom)\n",
    "        if isinstance(merged, LineString):\n",
    "            return merged\n",
    "        else:\n",
    "            raise ValueError(\"No se pudo convertir el MultiLineString a un solo LineString.\")\n",
    "    else:\n",
    "        raise TypeError(\"Geometría no soportada.\")\n",
    "\n",
    "def frechet_distance_ignore_direction(geom1, geom2):\n",
    "    geom1 = ensure_linestring(geom1)\n",
    "    geom2 = ensure_linestring(geom2)\n",
    "    dist_forward = frechet_distance(geom1, geom2)\n",
    "    dist_reverse = frechet_distance(geom1, LineString(list(geom2.coords)[::-1]))\n",
    "    return (dist_forward, 'normal') if dist_forward <= dist_reverse else (dist_reverse, 'invertida')\n",
    "\n",
    "# -----------------------------\n",
    "# Parámetros\n",
    "# -----------------------------\n",
    "umbral_porcentual = 0.01  # 1%\n",
    "output_csv = \"comparacion_lineas_por_nodos.csv\"\n",
    "\n",
    "# -----------------------------\n",
    "# Generar pares únicos de nodos\n",
    "# -----------------------------\n",
    "unique_pairs = set(\n",
    "    frozenset((row['INODE'], row['JNODE'])) for _, row in emme_links.iterrows()\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Escribir resultados en CSV\n",
    "# -----------------------------\n",
    "with open(output_csv, \"w\", newline='', encoding=\"utf-8\") as csvfile:\n",
    "    writer = csv.writer(csvfile, delimiter=';')\n",
    "    \n",
    "    # Encabezados\n",
    "    writer.writerow([\n",
    "        \"nodei\", \"nodej\", \"frechet_m\", \"direccion\",\n",
    "        \"longitud1_m\", \"longitud2_m\", \"longitud_promedio_m\",\n",
    "        \"diferencia_relativa_pct\", \"duplicadas\", \"atributos_iguales\"\n",
    "    ])\n",
    "    counter = 0\n",
    "    for pair in unique_pairs:\n",
    "        counter+=1\n",
    "        nodei, nodej = tuple(pair)\n",
    "        subset = emme_links[\n",
    "            ((emme_links['INODE'] == nodei) & (emme_links['JNODE'] == nodej)) |\n",
    "            ((emme_links['INODE'] == nodej) & (emme_links['JNODE'] == nodei))\n",
    "        ].reset_index(drop=True)\n",
    "\n",
    "        if len(subset) != 2:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            row1, row2 = subset.iloc[0], subset.iloc[1]\n",
    "            geom1 = ensure_linestring(row1.geometry)\n",
    "            geom2 = ensure_linestring(row2.geometry)\n",
    "\n",
    "            # Calcular distancia de Frechet\n",
    "            distance, direction = frechet_distance_ignore_direction(geom1, geom2)\n",
    "            len1 = geom1.length\n",
    "            len2 = geom2.length\n",
    "            len_prom = (len1 + len2) / 2\n",
    "            porcentaje = distance / len_prom\n",
    "            duplicadas = porcentaje <= umbral_porcentual\n",
    "\n",
    "            # Comparar atributos (excepto INODE, JNODE, geometry)\n",
    "            excluded = {\"ID\",\"INODE\", \"JNODE\", \"geometry\"}\n",
    "            common_columns = [col for col in emme_links.columns if col not in excluded]\n",
    "            if counter == 1:\n",
    "                print(\"Atributos comunes:\", common_columns)\n",
    "\n",
    "            atributos_iguales = row1[common_columns].equals(row2[common_columns])\n",
    "\n",
    "            # Escribir fila\n",
    "            writer.writerow([\n",
    "                nodei, nodej,\n",
    "                round(distance, 3),\n",
    "                direction,\n",
    "                round(len1, 2), round(len2, 2),\n",
    "                round(len_prom, 2),\n",
    "                round(porcentaje * 100, 2),\n",
    "                \"Sí\" if duplicadas else \"No\",\n",
    "                \"Sí\" if atributos_iguales else \"No\"\n",
    "            ])\n",
    "        except Exception as e:\n",
    "            writer.writerow([nodei, nodej, \"Error\", str(e)])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
